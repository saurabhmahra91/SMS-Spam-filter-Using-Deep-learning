{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55eb0bbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/2000703362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ggplot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import spacy\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "import statsmodels.api as sm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, learning_curve, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import os.path\n",
    "class SMSBase:\n",
    "    _nlp = spacy.load(\"en\")\n",
    "    \n",
    "    def __init__(self, filename, frac=0.8):\n",
    "        self._filename = filename\n",
    "        self._features = ['class', 'context']\n",
    "        \n",
    "        self._df_raw = pd.read_csv(self._filename, sep='\\t', names=self._features)\n",
    "        self.__format_context()\n",
    "        \n",
    "        self.__extract_features()\n",
    "        \n",
    "        self._group_by_feature = self._df_raw .groupby('class')\n",
    "        self._counts_by_features = self._group_by_feature.count().to_dict()['context']\n",
    "        \n",
    "        self.__split_test_train(frac)\n",
    "        \n",
    "    def __format_context(self):\n",
    "        self._df_raw['context'] =  self._df_raw['context'].map(lambda text : text.rstrip())\n",
    "        self._df_raw['context'] =  self._df_raw['context'].map(lambda text : text.replace(',', ' ,') if ',' in text else text)\n",
    "    \n",
    "    def __extract_features(self):\n",
    "        self._df_raw['len']= self._df_raw['context'].map(lambda text : len(text))\n",
    "        self._df_raw['n_words'] = self._df_raw['context'].map(lambda text : len(text.split(' ')))\n",
    "\n",
    "        self._features = self._df_raw.columns\n",
    "    \n",
    "    def __split_test_train(self, frac):\n",
    "        self._df_train = self._df_raw.sample(frac=frac)\n",
    "        self._df_test = self._df_raw.drop(self._df_train.index)\n",
    "    \n",
    "    def describe(self):\n",
    "        print('-' * 20 + 'Extended Dataset (Head)' + '-' * 20)\n",
    "        display(self._df_raw.head())\n",
    "        \n",
    "        print('-' * 20 + 'Extended Dataset (Describe)' + '-' * 20)\n",
    "        display(self._df_raw.describe())\n",
    "        \n",
    "        print('-' * 20 + 'Groupby Class (Describe)' + '-' * 20)\n",
    "        display(self._group_by_feature.describe())\n",
    "        \n",
    "    def create_lemmas(self, c):\n",
    "        tokens = self._nlp(c)\n",
    "        return [token.lemma_ for token in tokens]\n",
    "    \n",
    "    def create_tokens(self, c):\n",
    "        tokens = self._nlp(c)\n",
    "        return [token for token in tokens]\n",
    "    \n",
    "    \n",
    "class Util:\n",
    "        \n",
    "    def report_classification(model, df_train, df_test, X_features, y_feature):\n",
    "        classes_train = np.unique(df_train[y_feature].values).tolist()\n",
    "        classes_test = np.unique(df_test[y_feature].values).tolist()\n",
    "        \n",
    "        assert (classes_train == classes_test)\n",
    "        \n",
    "        classes = classes_train\n",
    "        \n",
    "        X_train = df_train[X_features].values.tolist()\n",
    "        X_test = df_test[X_features].values.tolist()\n",
    "        \n",
    "        y_train = df_train[y_feature].values.tolist()\n",
    "        y_test = df_test[y_feature].values.tolist()\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        report_cm(y_train, y_test, y_train_pred, y_test_pred, classes)\n",
    "        \n",
    "    def report_cm(y_train, y_test, y_train_pred, y_test_pred, classes):\n",
    "        figure, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "        cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "        df_cm_test = pd.DataFrame(cm_test, index = classes, columns = classes)\n",
    "        ax = sns.heatmap(df_cm_test, annot=True, ax = axes[0], square= True)\n",
    "        ax.set_title('Test CM')\n",
    "\n",
    "        cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "        df_cm_train = pd.DataFrame(cm_train, index = classes, columns = classes)\n",
    "        ax = sns.heatmap(df_cm_train, annot=True, ax = axes[1], square= True)\n",
    "        ax.set_title('Train CM')\n",
    "\n",
    "        print('-' * 20 + 'Testing Performance' + '-' * 20)\n",
    "        print(classification_report(y_test, y_test_pred, target_names = classes))\n",
    "        print('acc: ', metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "        print('-' * 20 + 'Training Performance' + '-' * 20)\n",
    "        print(classification_report(y_train, y_train_pred, target_names = classes))\n",
    "        print('acc: ', metrics.accuracy_score(y_train, y_train_pred))\n",
    "        \n",
    "    \n",
    "    def plot_cdf(p, \n",
    "             ax, \n",
    "             deltax=None, \n",
    "             xlog=False, \n",
    "             xlim=[0, 1], \n",
    "             deltay=0.25, \n",
    "             ylog=False, \n",
    "             ylim=[0,1], \n",
    "             xlabel = 'x'):\n",
    "\n",
    "        df = pd.DataFrame(p, columns=[xlabel])\n",
    "        display(df.describe())\n",
    "        \n",
    "        ecdf = sm.distributions.ECDF(p)\n",
    "        x = ecdf.x\n",
    "        y = ecdf.y\n",
    "        assert len(x) == len(y)\n",
    "        if deltax is not None:\n",
    "            x_ticks = np.arange(xlim[0], xlim[1] + deltax, deltax)\n",
    "            ax.set_xticks(x_ticks)\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xlim(xlim[0], xlim[1])\n",
    "        ax.vlines(np.mean(p), min(y), max(y), color='red', label='mean', linewidth=2)\n",
    "        ax.vlines(np.median(p), min(y), max(y), color='orange', label='median', linewidth=2)\n",
    "        ax.vlines(np.mean(p) + 2 * np.std(p), min(y), max(y), color='blue', label='mean + 2 * std', linewidth=2)\n",
    "        ax.vlines(np.mean(p) + 3 * np.std(p), min(y), max(y), color='green', label='mean + 3 * std', linewidth=2)\n",
    "\n",
    "        y_ticks = np.arange(ylim[0], ylim[1] + deltay, deltay)\n",
    "        ax.set_ylabel('CDF')\n",
    "        ax.set_yticks(y_ticks)\n",
    "        ax.set_ylim(ylim[0], ylim[1])\n",
    "\n",
    "        if xlog is True:\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "        if ylog is True:\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "\n",
    "        ax.grid(which='minor', alpha=0.5)\n",
    "        ax.grid(which='major', alpha=0.9)\n",
    "\n",
    "        ax.legend(loc=4)\n",
    "\n",
    "        sns.set_style('whitegrid')\n",
    "        sns.regplot(x=x, y=y, fit_reg=False, scatter=True, ax = ax)\n",
    "    \n",
    "        \n",
    "    def plot_class_dist(df, by):\n",
    "        \n",
    "        x_features = df.columns.drop(by)\n",
    "        assert 0 < len(x_features)\n",
    "        \n",
    "        x_features = x_features[0]\n",
    "        dist = df.groupby(by)[x_features].size() / len(df)\n",
    "        display(dist)        \n",
    "        sns.barplot(x=dist.index, y=dist.values)\n",
    "        \n",
    "    def plot_boxplot(df, by, y, ax):\n",
    "        ax = sns.boxplot(x=by, y=y, data=df[[by,  y]], ax = ax)\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "    def dump_pickle(obj,filename):\n",
    "        joblib.dump(obj, filename)\n",
    "        \n",
    "    def load_pickle(filename):\n",
    "        return joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43f48a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:37: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:46: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:69: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:37: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:46: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:69: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_12788/2849368732.py:29: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if option is 'NB':\n",
      "/tmp/ipykernel_12788/2849368732.py:37: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif option is 'SVM':\n",
      "/tmp/ipykernel_12788/2849368732.py:46: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif option is 'RFT':\n",
      "/tmp/ipykernel_12788/2849368732.py:69: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if option is 'SVM':\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SMSBase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/2849368732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSMSClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMSBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0m__pipelines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m__params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m__format_model_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_model.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SMSBase' is not defined"
     ]
    }
   ],
   "source": [
    "class SMSClassification(SMSBase):\n",
    "    __pipelines = {}\n",
    "    __params = {}\n",
    "    __format_model_file_name = '{}_model.pkl'\n",
    "\n",
    "    def __init__(self, filename, frac=0.8):\n",
    "        super().__init__(filename, frac)\n",
    "        \n",
    "        self.__bow = CountVectorizer(analyzer=self.create_lemmas)\n",
    "        self.__tfidf = TfidfTransformer()\n",
    "        \n",
    "        self.__svd = TruncatedSVD(n_components=50)\n",
    "\n",
    "        self.__cv = StratifiedKFold(n_splits=10)\n",
    "        \n",
    "        self.__default_params = {\n",
    "            'tfidf__use_idf': (True, False),\n",
    "            'bow__analyzer': (self.create_lemmas, self.create_tokens),\n",
    "        }\n",
    "        \n",
    "        self.__X = self._df_train['context'].values.tolist()\n",
    "        self.__y = self._df_train['class'].values.tolist()\n",
    "        \n",
    "   \n",
    "    def __create_pipeline(self, option='NB'):\n",
    "                        \n",
    "        if (option in self.__pipelines) is False:\n",
    "                        \n",
    "            if option is 'NB':\n",
    "                classifier = MultinomialNB()\n",
    "                pipeline = Pipeline([\n",
    "                    ('bow', self.__bow),\n",
    "                    ('tfidf', self.__tfidf),\n",
    "                    ('classifier', classifier),\n",
    "                ])\n",
    "\n",
    "            elif option is 'SVM':\n",
    "                classifier = SVC()\n",
    "                pipeline = Pipeline([\n",
    "                    ('bow', self.__bow),\n",
    "                    ('tfidf', self.__tfidf),\n",
    "                    ('svd', self.__svd),\n",
    "                    ('classifier', classifier),\n",
    "                ])\n",
    "                \n",
    "            elif option is 'RFT':\n",
    "                classifier = RandomForestClassifier()\n",
    "                pipeline = Pipeline([\n",
    "                    ('bow', self.__bow),\n",
    "                    ('tfidf', self.__tfidf),\n",
    "                    ('svd', self.__svd),\n",
    "                    ('classifier', classifier),\n",
    "                ])\n",
    "                \n",
    "            else:\n",
    "                classifier = MultinomialNB()\n",
    "\n",
    "            self.__pipelines[option] = pipeline\n",
    "            \n",
    "            return pipeline\n",
    "\n",
    "        else:\n",
    "            return self.__pipelines[option]\n",
    "            \n",
    "            \n",
    "    def __create_grid_search_params(self, option='NB'):\n",
    "        \n",
    "        if (option in self.__params) is False:\n",
    "            if option is 'SVM':\n",
    "                params = [\n",
    "                    {\n",
    "                      'classifier__C': [1, 10, 100, 1000], \n",
    "                      'classifier__kernel': ['linear']\n",
    "                    },\n",
    "                    {\n",
    "                      'classifier__C': [1, 10, 100, 1000], \n",
    "                      'classifier__gamma': [0.001, 0.0001], \n",
    "                      'classifier__kernel': ['rbf']\n",
    "                    },\n",
    "                ]\n",
    "            else:\n",
    "                params = self.__default_params\n",
    "\n",
    "            self.__params[option] = params\n",
    "        else:\n",
    "            params = self.__params[option]\n",
    "            \n",
    "        return params\n",
    "\n",
    "        \n",
    "        \n",
    "    def validate(self, option='NB'):\n",
    "        \n",
    "        pipeline = self.__create_pipeline(option)\n",
    "        if pipeline is not None:            \n",
    "            scores = cross_val_score(pipeline, \n",
    "                                     self.__X, \n",
    "                                     self.__y, \n",
    "                                     scoring='accuracy', \n",
    "                                     cv=self.__cv, \n",
    "                                     verbose=1, \n",
    "                                     n_jobs=-1)\n",
    "\n",
    "            print('scores={}\\nmean={} std={}'.format(scores, scores.mean(), scores.std()))\n",
    "        else:\n",
    "            print (\"pipeline does not exist!\")\n",
    "\n",
    "        \n",
    "    def train(self, option='NB', dump=True):\n",
    "        \n",
    "        pipeline = self.__create_pipeline(option)\n",
    "        if pipeline is not None:\n",
    "            \n",
    "            params = self.__create_grid_search_params(option)\n",
    "            \n",
    "            grid = GridSearchCV(\n",
    "                pipeline, \n",
    "                params, \n",
    "                refit=True, \n",
    "                n_jobs=-1, \n",
    "                scoring='accuracy', \n",
    "                cv=self.__cv)\n",
    "\n",
    "            model = grid.fit(self.__X, self.__y)\n",
    "            \n",
    "            display('(Grid Search) Best Parameters:', )\n",
    "            display(pd.DataFrame([model.best_params_]))\n",
    "\n",
    "            if dump:\n",
    "                model_file_name = self.__format_model_file_name.format(option)\n",
    "                Util.dump_pickle(model, model_file_name)\n",
    "                \n",
    "            return model\n",
    "                \n",
    "        else:\n",
    "            print('pipeline does not exist!')\n",
    "            return None\n",
    "\n",
    "    \n",
    "    def test(self, X=None, model=None, model_file=None):\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.__X\n",
    "        \n",
    "        if model is None and model_file is None:\n",
    "            print('Please, use either model or model_file')\n",
    "            return []\n",
    "        \n",
    "        if model_file is not None and os.path.isfile(model_file):\n",
    "            model = Util.load_pickle(model_file)\n",
    "            print('{} file was loaded'.format(model_file))\n",
    "            return model.predict(X)\n",
    "        \n",
    "        if model is not None:\n",
    "            return model.predict(X)\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86084e9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMSClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/738579555.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMSClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SMSSpam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SMSClassification' is not defined"
     ]
    }
   ],
   "source": [
    "sms = SMSClassification('SMSSpam')\n",
    "sms.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ccaa53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/1691614654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_class_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Util' is not defined"
     ]
    }
   ],
   "source": [
    "Util.plot_class_dist(sms._df_raw, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a8aa1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/723733141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_words_in_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m Util.plot_cdf(n_words_in_context, \n\u001b[1;32m      5\u001b[0m          \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sms' is not defined"
     ]
    }
   ],
   "source": [
    "n_words_in_context = sms._df_raw['n_words'].values.tolist()\n",
    "\n",
    "figure, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "Util.plot_cdf(n_words_in_context, \n",
    "         axes[0], \n",
    "         xlim=[0, np.mean(n_words_in_context) + 3 * np.std(n_words_in_context) + 50],\n",
    "         deltay = 0.05,\n",
    "         ylim=[0, 1.00], xlabel='number of words')\n",
    "\n",
    "Util.plot_boxplot(sms._df_raw, 'class', 'n_words', axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "201823da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12788/3173054762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen_of_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m Util.plot_cdf(len_of_context, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'sms' is not defined"
     ]
    }
   ],
   "source": [
    "len_of_context = sms._df_raw['len'].values.tolist()\n",
    "\n",
    "figure, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "Util.plot_cdf(len_of_context, \n",
    "         axes[0], \n",
    "         xlim=[0, np.mean(len_of_context) + 3 * np.std(len_of_context) + 50],\n",
    "         deltay = 0.05,\n",
    "         ylim=[0, 1.00], xlabel='len of context')\n",
    "\n",
    "Util.plot_boxplot(sms._df_raw, 'class', 'len', axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa5b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
